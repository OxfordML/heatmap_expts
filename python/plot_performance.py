'''
Plot the results of the simulations with increasing numbers of data points. Show accuracy etc. 

Currently using the results generated by expmt_module -- can alter to use the Ushahidi and Cicada data later.

Created on 23 Nov 2015

@author: edwin
'''

import numpy as np
import matplotlib.pyplot as plt
import logging

# import gen_synthetic as expmt_module
#import ushahidi_loader_damage as expmt_module
import ushahidi_loader_emergencies as expmt_module

if hasattr(expmt_module, 'cluster_spreads'):
    cluster_spreads = expmt_module.cluster_spreads
else:
    cluster_spreads = [0]

nruns = expmt_module.nruns
if hasattr(expmt_module, 'weak_proportions'):
    weak_proportions = expmt_module.weak_proportions
else:
    weak_proportions = [-1]

def load_mean_results(nruns, weak_proportions, filename):
    mean_results = {}
    for p_idx, p in enumerate(weak_proportions):
        for cluster_spread in cluster_spreads:
            for d in range(nruns):
                if p==-1:
                    dataset_label = "d%i" % d # no proportion indices
                else:
                    dataset_label = "p%i_d%i" % (p_idx, d)
                
                expt_label = expmt_module.expt_label_template
                if '%' in expt_label:
                    expt_label = expt_label % cluster_spread
                     
                logging.info("Loading results for proportion %i, Dataset %d, cluster spread %f" % (p_idx, d, cluster_spread))
                outputdir, _ = expmt_module.dataset_location(expt_label, dataset_label)
    
                current_results = np.load(outputdir + filename).item()
                methods = current_results.keys()
    
                if p not in mean_results:
                    mean_results[p] = {}
                    
                if cluster_spread not in mean_results[p]:
                    mean_results[p][cluster_spread] = {}                

                for m in methods:
                    if not m in mean_results[p][cluster_spread]:
                        mean_results[p][cluster_spread][m] = np.array(current_results[m])
                    else:
                        mean_results[p][cluster_spread][m] += np.array(current_results[m])
        
            for m in mean_results[p][cluster_spread]:
                mean_results[p][cluster_spread][m] = mean_results[p][cluster_spread][m] / float(nruns)
    return mean_results, methods

if __name__ == '__main__':
    # import settings from where the experiments were run    
    Nreps_initial = expmt_module.Nreps_initial
    Nrep_inc = expmt_module.Nrep_inc
    if hasattr(expmt_module, 'Nreports'):
        Nreports = expmt_module.Nreports
    else:
        _, Nreports, _, _, _, _ = expmt_module.load_data()
          
    if hasattr(expmt_module, 'nsteps'):
        Nsteps = expmt_module.nsteps
    else:
        Nsteps = (Nreports - Nreps_initial) / float(Nrep_inc) + 1
    
    # get a set of x-coordinates for the number of reports at each iteration
    Nreps_iter = np.arange(Nsteps) * Nrep_inc + Nreps_initial
    
    # load results for the density estimation        
    # Root mean squared error
    rmsed, methods = load_mean_results(nruns, weak_proportions, "rmsed.npy")
     
    for p in weak_proportions:
        for cs in cluster_spreads:
            plt.figure()
            plt.title('Root Mean Square Error of Density Estimates')
            for m in methods:
                plt.plot(Nreps_iter, rmsed[p][cs][m], label='%.2f reliable, %s' % (p, m))
            plt.xlabel('Number of crowdsourced labels')
            plt.ylabel('RMSE')
            plt.ylim(0, 1.0)
            plt.legend(loc='best')
     
    # Kendall's Tau
    tau, methods = load_mean_results(nruns, weak_proportions, "tau.npy")
 
    for p in weak_proportions:
        for cs in cluster_spreads:        
            plt.figure()
            plt.title("Kendall's Tau for Density Estimates")
            for m in methods:
                plt.plot(Nreps_iter, tau[p][cs][m], label='%.2f reliable, %s' % (p, m))
            plt.xlabel('Number of crowdsourced labels')
            plt.ylabel('tau')
            plt.ylim(-1.0, 1.0)
            plt.legend(loc='best')
      
    # Mean Cross Entropy
    mced, methods = load_mean_results(nruns, weak_proportions, "mced.npy")
    
    for p in weak_proportions:
        for cs in cluster_spreads:        
            plt.figure()
            plt.title("Mean Cross Entropy of Density Estimates")
            for m in methods:
                plt.plot(Nreps_iter, mced[p][cs][m], label='%.2f reliable, %s' % (p, m))
            plt.xlabel('Number of crowdsourced labels')
            plt.ylabel('MCE')
            plt.legend(loc='best')    
    
    # load results for predicting individual data points
    # Brier score
    rmse, methods = load_mean_results(nruns, weak_proportions, "rmse.npy")   
    for p in weak_proportions:
        for cs in cluster_spreads:        
            plt.figure()
            plt.title("Brier Score on Individual Data Points")
            for m in methods:
                plt.plot(Nreps_iter, rmse[p][cs][m], label='%.2f reliable, %s' % (p, m))
            plt.xlabel('Number of crowdsourced labels')
            plt.ylabel('Brier Score')
            plt.ylim(0, 1.0)
            plt.legend(loc='best')    
         
    # AUC
    auc, methods = load_mean_results(nruns, weak_proportions, "auc.npy")
    for p in weak_proportions:
        for cs in cluster_spreads:        
            plt.figure()
            plt.title("AUC when Predicting Individual Data Points")
            for m in methods:
                plt.plot(Nreps_iter, auc[p][cs][m], label='%.2f reliable, %s' % (p, m))
            plt.xlabel('Number of crowdsourced labels')
            plt.ylabel('AUC')
            plt.ylim(0, 1.0)
            plt.legend(loc='best')    
     
    # Mean cross entropy
    mce, methods = load_mean_results(nruns, weak_proportions, "mce.npy")
    for p in weak_proportions:
        for cs in cluster_spreads:        
            plt.figure()
            plt.title("Mean Cross Entropy of Individual Data Points")
            for m in methods:
                plt.plot(Nreps_iter, mce[p][cs][m], label='%.2f reliable, %s' % (p, m))
            plt.xlabel('Number of crowdsourced labels')
            plt.ylabel('MCE')
            plt.legend(loc='best')    
        
    # Variances within a single dataset
    #rmse_var = load_mean_results(nruns, weak_proportions, "rmse_var.npy")
    #auc_var = load_mean_results(nruns, weak_proportions, "auc_var.npy")
    #mce_var = load_mean_results(nruns, weak_proportions, "mce_var.npy")    