'''
Plot the results of the simulations with increasing numbers of data points. Show accuracy etc. 

Currently using the results generated by expmt_module -- can alter to use the Ushahidi and Cicada data later.

Created on 23 Nov 2015

@author: edwin
'''

import numpy as np

import matplotlib
#import matplotlib.pyplot as plt
matplotlib.use('Agg')
plt = matplotlib.pyplot

import logging

import run_synthetic_bias as expmt_module
#import run_synthetic_noise as expmt_module
# import ushahidi_loader_damage as expmt_module
#import ushahidi_loader_emergencies as expmt_module
#import prn_simulation as expmt_module

if hasattr(expmt_module, 'cluster_spreads'):
    cluster_spreads = expmt_module.cluster_spreads
elif hasattr(expmt_module, 'featurenames'):
    cluster_spreads = [expmt_module.featurenames[0]]
else:
    cluster_spreads = [0]

nruns = expmt_module.nruns
if hasattr(expmt_module, 'weak_proportions'):
    weak_proportions = expmt_module.weak_proportions
else:
    weak_proportions = [-1]

def get_output_dir(d, p, p_idx, cluster_spread):
    if p==-1:
        dataset_label = "d%i" % d # no proportion indices
    else:
        dataset_label = "p%f_d%i" % (p, d)
    
    expt_label = expmt_module.expt_label_template
    if '%' in expt_label:
        expt_label = expt_label % cluster_spread
         
    logging.info("Loading results for proportion %f, Dataset %d, cluster spread %s" % (p, d, str(cluster_spread)))
    outputdir, _ = expmt_module.dataset_location(expt_label, dataset_label)
    return outputdir

def load_mean_results(nruns, cluster_spread, weak_proportions, Nreps_iter, filename):
    mean_results = {}
    std_results = {}

    for p_idx, p in enumerate(weak_proportions):
        for d in range(nruns):
            outputdir = get_output_dir(d, p, p_idx, cluster_spread)
    
            current_results = np.load(outputdir + filename).item()
            methods = current_results.keys()
                  
            for m in methods:
                if not m in mean_results:
                    mean_results[m] = np.zeros((len(weak_proportions), len(Nreps_iter), nruns))
                    std_results[m] = np.zeros((len(weak_proportions), len(Nreps_iter), nruns))
            
                if len(current_results[m])==24 and len(Nreps_iter)==11:
                    current_results[m] = np.array(current_results[m])[[0,2,4,6,8,10,12,14,16,18,20]] 
                mean_results[m][p_idx, :, d] = current_results[m]
                std_results[m][p_idx, :, d] = current_results[m]
    
    for m in methods:          
        mean_results[m] = np.mean(mean_results[m], axis=2)
        print "loader"
        print mean_results[m][1, 0]
        std_results[m] = np.std(std_results[m], axis=2)
        print std_results[m][1,0]
    return mean_results, std_results, methods

def plot_performance(Nreps_iter, cluster_spreads, filename, title, ylabel, outfilename):
    
    rmsed, rmsed_std, methods = load_mean_results(nruns, cluster_spreads[0], weak_proportions, Nreps_iter, filename)

    for l_idx, l in enumerate(Nreps_iter):
        for cs in cluster_spreads:
            plt.figure()
            plt.title(title)
            for i, m in enumerate(methods):
                label = m  
                print "plotter"
                print rmsed[m][:,l_idx]
                plt.plot(weak_proportions, rmsed[m][:, l_idx], label=label, color=colors[i])
            plt.xlabel('Proportion of Reliable Reporters')
            plt.ylabel(ylabel)
            #plt.ylim(0, 1.0)
            plt.legend(loc='best')
            plt.grid(True)
            for i, m in enumerate(methods):
                plt.fill_between(weak_proportions, rmsed[m][:, l_idx] - rmsed_std[m][:, l_idx], rmsed[m][:, l_idx] + rmsed_std[m][:, l_idx], 
                                 alpha=0.2, edgecolor=colors[i], facecolor=colors[i])           
            
            outputdir = get_output_dir(0, weak_proportions[0], 0, cs)
            plt.savefig(outputdir + "/%s_%i.pdf" % (outfilename, l))
      

if __name__ == '__main__':
    if hasattr(expmt_module, 'Nreports'):
        Nreports = expmt_module.Nreports
    else:
        _, Nreports, _, _, _, _ = expmt_module.load_data()
    
    # import settings from where the experiments were run
    if hasattr(expmt_module, "Nreps_initial"):
        Nreps_initial = expmt_module.Nreps_initial
    else:
        Nreps_initial = expmt_module.Nreps_initial_fraction * Nreports
        
    if Nreps_initial < 1:
        Nreps_initial = Nreps_initial * Nreports # Nreps_initial is the initial fraction
        
    if hasattr(expmt_module, 'Nrep_inc'):
        Nrep_inc = expmt_module.Nrep_inc
    else:
        Nrep_inc = (Nreports - Nreps_initial) / (expmt_module.nsteps - 1) 
          
    if hasattr(expmt_module, 'nsteps'):
        Nsteps = expmt_module.nsteps
    else:
        Nsteps = (Nreports - Nreps_initial) / float(Nrep_inc) + 1
    
    # get a set of x-coordinates for the number of reports at each iteration
    Nreps_iter = np.arange(Nsteps) * Nrep_inc + Nreps_initial
    
    colors = ['b', 'g', 'r', 'purple', 'deepskyblue', 'saddlebrown', 'darkorange']    
    
    # load results for the density estimation        
    # Root mean squared error
    plot_performance(Nreps_iter, cluster_spreads, "rmsed.npy", 'Root Mean Square Error of Density Estimates', 
                        'RMSE', 'rmsed_p')

    # Kendall's Tau
    plot_performance(Nreps_iter, cluster_spreads, "tau.npy", "Kendall's Tau for Density Estimates", 
                        'tau', 'tau_p')    
       
    # Mean Cross Entropy
    plot_performance(Nreps_iter, cluster_spreads, "mced.npy", "Negative Log Probability Density of Density Estimates", 
                        'NLPD or Cross Entropy (bits)', 'mce_density_p')
     
    # load results for predicting individual data points
    # Brier score
    plot_performance(Nreps_iter, cluster_spreads, "rmse.npy", "Brier Score", 'Brier score', 'brier_p')
         
    # AUC
    plot_performance(Nreps_iter, cluster_spreads, "auc.npy", "AUC", 'AUC', 'auc_p')
     
    # Mean cross entropy
    plot_performance(Nreps_iter, cluster_spreads, "mce.npy", "Cross Entropy (Negative Log Probability) of Classification",
                     'Cross Entropy (bits)', 'mce_discrete_p')
 
    # Accuracy
    plot_performance(Nreps_iter, cluster_spreads, "acc.npy", "Classification Accuracy", 
                    'Fraction of points correctly classified', 'acc_p')
                     
    # Variances within a single dataset
    #rmse_var = load_mean_results(nruns, weak_proportions, "rmse_var.npy")
    #auc_var = load_mean_results(nruns, weak_proportions, "auc_var.npy")
    #mce_var = load_mean_results(nruns, weak_proportions, "mce_var.npy")    
